{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import imp\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Outline\n",
    "\n",
    "- Motivation\n",
    "- Basics of Neural Networks\n",
    "  - Forward Propagation\n",
    "  - Backward Propagation\n",
    "- Deep Neural Networks\n",
    "  - Convolutional Neural Networks\n",
    "  - **Recurrent Neural Networks** \n",
    "- Applications\n",
    "  - Computer Vision\n",
    "  - Natural Language Processing\n",
    "  - Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Outline: Recurrent Neural Networks\n",
    "- Introduction\n",
    "- Standard RNN\n",
    "  - Forward Propagation\n",
    "  - Backward Propagation\n",
    "- Long Short-Term Memory (LSTM)\n",
    "- Example: Character-level language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Recurrent Neural Networks (RNN)\n",
    "- A special kind of neural network designed for modeling sequential data\n",
    "  - Can take arbitrary number of inputs\n",
    "  - Can produce arbitrary number of outputs\n",
    "- Examples of sequential problems\n",
    "  - Machine translation\n",
    "  - Speech recognition\n",
    "  - Image caption generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Outline: Recurrent Neural Networks\n",
    "- Introduction\n",
    "- **Standard RNN**\n",
    "  - **Forward Propagation**\n",
    "  - Backward Propagation\n",
    "- Long Short-Term Memory (LSTM)\n",
    "- Example: Character-level language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Forward Propagation\n",
    "<img src=\"images/simple_rnn_fprop.png\" width=700px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Forward Propagation\n",
    "$$ \\textbf{h}_t = f(\\textbf{W}\\textbf{x}_t + \\textbf{U}\\textbf{h}_{t-1}+\\textbf{b}) $$\n",
    "$$ \\hat{\\textbf{y}}_t = \\textbf{V}\\textbf{h}_t + \\textbf{b}' $$\n",
    "$$ \\mathcal{L} = \\sum_{t=1}^{T} \\mathcal{L}_t \\left( \\textbf{y}_t, \\hat{\\textbf{y}}_t \\right) $$\n",
    "- $\\textbf{W}$: input weight, $\\textbf{U}$: recurrent weight, $\\textbf{V}$: output weight, $\\textbf{b},\\textbf{b}'$: bias, $f$: non-linear activation (e.g., ReLU)\n",
    "- Weights are shared across time: the number of parameters does not depend on the length of input/output sequence\n",
    "<img src=\"images/simple_rnn.png\" width=500px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Outline: Recurrent Neural Networks\n",
    "- Introduction\n",
    "- Standard RNN\n",
    "  - Forward Propagation\n",
    "  - **Backward Propagation**\n",
    "- Long Short-Term Memory (LSTM)\n",
    "- Example: Character-level language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Backpropagation Through Time (BPTT)\n",
    "- Gradient w.r.t. hidden units (assuming that $\\frac{\\partial \\mathcal{L}}{\\partial \\textbf{h}_{t+1}}$ is given)\n",
    "$$ \\frac{\\partial\\mathcal{L}}{\\partial \\textbf{h}_t} = \\sum_{\\tau=t}^{T}\\frac{\\partial\\mathcal{L}_{\\tau}}{\\partial \\textbf{h}_t} \\mbox { } (\\because \\frac{\\partial\\mathcal{L}_k}{\\partial \\textbf{h}_t}=0 \\mbox { if } k < t)$$ \n",
    "$$ \\frac{\\partial\\mathcal{L}}{\\partial \\textbf{h}_t} = \\frac{\\partial \\mathcal{L}_t}{\\partial \\textbf{h}_t} + \\frac{\\partial \\textbf{h}_{t+1}}{\\partial \\textbf{h}_{t}} \\frac{\\partial \\sum_{\\tau=t+1}^{T}\\mathcal{L}_{\\tau}}{\\partial \\textbf{h}_{t+1}}  \\\\\n",
    "= \\underbrace{\\frac{\\partial \\mathcal{L}_t}{\\partial \\hat{\\textbf{y}}_t}}_{\\mbox{easy}}\\underbrace{\\frac{{\\partial \\hat{\\textbf{y}}_t}}{\\partial \\textbf{h}_t}}_{\\mbox{easy}} + \\underbrace{\\frac{\\partial \\textbf{h}_{t+1}}{\\partial \\textbf{h}_{t}}}_{\\mbox{easy}} \\underbrace{\\frac{\\partial \\mathcal{L}}{\\partial \\textbf{h}_{t+1}}}_{\\mbox{given}} $$\n",
    "<img src=\"images/simple_rnn_fprop.png\" width=500px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Backpropagation Through Time (BPTT)\n",
    "- Gradient w.r.t. input units (given $\\frac{\\partial \\mathcal{L}}{\\partial \\textbf{h}_{t}}$)\n",
    "$$ \\frac{\\partial\\mathcal{L}}{\\partial \\textbf{x}_t} = \\frac{\\partial \\mathcal{L}}{\\partial \\textbf{h}_t}\\frac{\\partial \\textbf{h}_t}{\\partial \\textbf{x}_t} $$\n",
    "<img src=\"images/simple_rnn_fprop.png\" width=500px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Backward Propagation\n",
    "<img src=\"images/simple_rnn_back2.png\" width=700px align=\"middle\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Backward Propagation\n",
    "<img src=\"images/simple_rnn_back3.png\" width=700px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Backward Propagation\n",
    "<img src=\"images/simple_rnn_back4.png\" width=700px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Backward Propagation\n",
    "<img src=\"images/simple_rnn_back5.png\" width=700px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Backward Propagation\n",
    "<img src=\"images/simple_rnn_back6.png\" width=700px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Backward Propagation\n",
    "<img src=\"images/simple_rnn_back7.png\" width=700px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Backpropagation Through Time (BPTT)\n",
    "- Gradient w.r.t. weights\n",
    "  - Recall: The weights are shared through time. Gradients of shared weights should be accumulated!\n",
    "  \n",
    "<font color='red'>$ \\frac{\\partial \\mathcal{L}}{\\partial \\textbf{V}} = \\sum_{t=1}^{T}\\frac{\\partial \\mathcal{L}}{\\partial \\hat{\\textbf{y}}_t}\\frac{\\partial \\hat{\\textbf{y}}_t}{\\partial \\textbf{V}} $ </font> <font color='blue'>$ \\frac{\\partial \\mathcal{L}}{\\partial \\textbf{W}} = \\sum_{t=1}^{T}\\frac{\\partial \\mathcal{L}}{\\partial \\textbf{h}_t}\\frac{\\partial \\textbf{h}_t}{\\partial \\textbf{W}} $ </font> <font color='green'>$ \\frac{\\partial \\mathcal{L}}{\\partial \\textbf{U}} = \\sum_{t=1}^{T-1}\\frac{\\partial \\mathcal{L}}{\\partial \\textbf{h}_{t+1}}\\frac{\\partial \\textbf{h}_{t+1}}{\\partial \\textbf{U}} $ </font>\n",
    "<img src=\"images/simple_rnn_back_w.png\" width=600px/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Summary of Standard Recurrent Neural Network\n",
    "- RNN is actually not much different from a standard (feedforward) neural network except that:\n",
    "  - Input/output are given through time.\n",
    "  - Weights are extensively shared.\n",
    "- RNN can be viewed as a very deep feedforward neural network with shared weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Outline: Recurrent Neural Networks\n",
    "- Introduction\n",
    "- Standard RNN\n",
    "  - Forward Propagation\n",
    "  - Backward Propagation\n",
    "- **Long Short-Term Memory (LSTM)**\n",
    "- Example: Character-level language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Vanshing Gradient Problem\n",
    "- RNN can model arbitrary sequences if properly trained.\n",
    "- In practice, it is difficult to train an RNN to learn long-term dependencies because of vanishing gradient.\n",
    "- Intuition of vanishing gradient\n",
    "  - A hidden unit activation is not well-preserved to the long-term future (forward propagation view)\n",
    "  - Gradients are diffused through time (backward propagation view)\n",
    "![](images/vanish_rnn.png)\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Alex Graves)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Long Short-Term Memory (LSTM)\n",
    "- A special type of RNN that can handle vanishing gradient better.\n",
    "- $i_t,o_t,f_t$: **input gate**, **output gate**, and **forget gate**\n",
    "- $c_t$: **memory cell** containing information about history of inputs\n",
    "- $h_t$: output activation\n",
    "<img src=images/lstm.png width=700px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Alex Graves)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Long Short-Term Memory (LSTM)\n",
    "- Gating mechanism\n",
    "  - Input gate: whether to ignore a new input or not\n",
    "  - Output gate: whether to produce an output or not (while preserving the memory cell)\n",
    "  - Forget gate: whether to erase the memory cell or not\n",
    "- Gating is controlled by LSTM's weights that are also learned from data.\n",
    "![](images/vanish_lstm.png)\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Alex Graves)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Outline: Recurrent Neural Networks\n",
    "- Introduction\n",
    "- Simple RNN\n",
    "  - Forward Propagation\n",
    "  - Backward Propagation\n",
    "- Long Short-Term Memory (LSTM)\n",
    "- **Example: Character-level language modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Character-level language modeling\n",
    "- Goal: build a character-level generative model\n",
    "- A character ($x_t$) is represented as a one-of-k vector (k: #characters).\n",
    "$$ P(x_1,x_2,...,x_T) = \\prod_{t=1}^{T}P(x_{t}|x_{t-1},...,x_1) \\approx \\prod_{t=1}^{T}P(x_{t}|x_{t-1},...,x_{t-n}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Character-level language modeling\n",
    "- RNN is trained to predict next character given previous characters\n",
    "- Maximizing the likelihood can be formulated as minimizing sum of cross entropy losses.\n",
    "$$ \\mathcal{L}(\\textbf{x}) = -\\sum_{t=1}^{T}\\log P(x_{t}|x_{t-1},...,x_{t-n}; \\theta) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Character-level language modeling\n",
    "- After training, the network can \"sample\" characters from the multinomial distribution of characters at the output layer (softmax).\n",
    "<img src=\"images/char_rnn.png\" width=800px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Shakespeare\n",
    "<img src=\"images/char_rnn2.png\" width=700px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Richard Socher)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Wikipedia\n",
    "<img src=\"images/char_rnn3.png\" width=900px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Richard Socher)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Latex\n",
    "<img src=\"images/char_rnn4.png\" width=900px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Richard Socher)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### C++ Code\n",
    "<img src=\"images/char_rnn5.png\" width=900px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Richard Socher)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Outline\n",
    "\n",
    "- Motivation\n",
    "- Basics of Neural Networks\n",
    "  - Forward Propagation\n",
    "  - Backward Propagation\n",
    "- Deep Neural Networks\n",
    "  - Convolutional Neural Networks\n",
    "  - Recurrent Neural Networks\n",
    "- Applications\n",
    "  - **Computer Vision** \n",
    "  - Natural Language Processing\n",
    "  - Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Object Detection\n",
    "- Goal: find bounding boxes that contain objects in an image and predict their classes.\n",
    "- CNN approaches have recently achieved state-of-the-art results on object detection task.\n",
    "- Example: Regions with CNN\n",
    "  - Use a low-level region proposal methods to generate many candidate bounding boxes\n",
    "  - Use a pre-trained CNN to classify each region\n",
    "<img src=\"images/object_detection.png\" width=1000px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Girshick et al, \"Reigion-based Convolutional Networks for Accurate Object Detection and Semantic Segmentation\", PAMI, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Object Detection\n",
    "<img src=\"images/object_detection2.png\" width=800px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figur from Ross Girshick)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Object Segmentation\n",
    "- Goal: Segment object regions and predict class labels for each region\n",
    "- Can be formulated as pixel-wise classification \n",
    "- CNN is pre-trained on a large-scale classification dataset (ImageNet)\n",
    "<img src=\"images/object_segmentation.png\" width=800px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Long et al, \"Fully Convolutional Networks for Semantic Segmentation\", CVPR, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Object Segmentation\n",
    "<img src=\"images/object_segmentation3.png\" width=650px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Noh et al, \"Learning Deconvolution Network for Semantic Segmentation\", ICCV, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Neural Network as Generative Model\n",
    "- Goal\n",
    "$$\\max_{\\theta} \\mathbb{E}_{\\textbf{x}} \\left[\\log P\\left(\\textbf{x} ; \\theta \\right)\\right]$$\n",
    "- Outcome\n",
    "$$\\textbf{x} \\sim P\\left(\\textbf{x} ; \\theta \\right)$$\n",
    "\n",
    "<span style=\"width:1000px\"> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " ### Image Generation: DRAW Network (Gregor et al.)\n",
    "- Introduce a differentiable visual attention mechanism\n",
    "- The network is trained to reconstruct a given image through multiple time steps. \n",
    "- At each time-step, the network is forced to read/write only a part of the image (using attention windows).\n",
    "- An intermediate hidden layer ($z_t$) is encouraged to follow a Gaussian distribution.\n",
    "- After training, we sample $z_t$ from a Gaussian distribution to generate an image.\n",
    "<img src=\"images/draw.png\" width=600px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Gregor et al, \"DRAW: A Recurrent Neural Network For Image Generation\", ICML, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Image Generation: Generative Adversarial Network (Goodfellow et al.)\n",
    "- Model : Generator (G), Discriminator (D)\n",
    "- Generator (G) : Learns to generate realistic images\n",
    "- Discriminator (D) : Learns to classify whether a given image is real (from data) or not (from model)\n",
    "- Objective : Fool each other!\n",
    "<img src=\"images/gan.png\" width=1000px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Image Generation: Generative Adversarial Network (Radford et al.)\n",
    "<img src=\"images/gan2.png\" width=1000px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Radford et al, \"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\", ICLR, 2016.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Image Generation: Generative Adversarial Network (Radford et al.)\n",
    "<img src=\"images/gan3.png\" width=1000px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Radford et al, \"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\", ICLR, 2016.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Video Prediction (Oh et al.)\n",
    "- Goal: Predict future frames given previous frames and actions in Atari games.\n",
    "<img src=\"images/video_prediction.png\" />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Oh et al, \"Action-Conditional Video Prediction using Deep Networks in Atari Games\", NIPS, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Outline\n",
    "\n",
    "- Motivation\n",
    "- Basics of Neural Networks\n",
    "  - Forward Propagation\n",
    "  - Backward Propagation\n",
    "- Deep Neural Networks\n",
    "  - Convolutional Neural Networks\n",
    "  - Recurrent Neural Networks\n",
    "- Applications\n",
    "  - Computer Vision\n",
    "  - **Natural Language Processing**\n",
    "  - Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Sequence-to-Sequence Learning Framework (Sutskever et al.)\n",
    "- A general RNN framework for sequence-to-sequence prediction\n",
    "- ex) $x$: English sentence, $y$: French sentence in machine translation\n",
    "$$ P \\left(y_1, y_2, ... , y_{T'} \\vert x_1, x_2, ..., x_{T} \\right)$$\n",
    "<img src=\"images/seq_to_seq.png\" />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Sutskever et al, \"Sequence to Sequence Learning with Neural Networks\", NIPS, 2014.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Seq2Seq: Application to Machine Translation (Sutskever et al.)\n",
    "- Achieves the state-of-the-art results on English-to-French dataset.\n",
    "<img src=\"images/seq_to_seq2.png\" width=800px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Sutskever et al, \"Sequence to Sequence Learning with Neural Networks\", NIPS, 2014.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Seq2Seq: Application to Grammar Parsing (Vinyals et al.)\n",
    "- A parsing tree can be represented as a sequence.\n",
    "- Seq2Seq framework can be applied (sentence $\\rightarrow$ parse tree)\n",
    "<img src=\"images/grammar.png\" width=800px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Vinyals et al, \"Grammar as a Foreign Language\", NIPS, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Seq2Seq: Application to Grammar Parsing (Vinyals et al.)\n",
    "\n",
    "<img src=\"images/grammar2.png\" width=800px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Vinyals et al, \"Grammar as a Foreign Language\", NIPS, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Seq2Seq: Application to Program Execution (Zaremba et al.)\n",
    "- Input: source code (characters)\n",
    "- Output: execution result (characters)\n",
    "<img src=\"images/python.png\" />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Zaremba et al., \"Learning to Execute\", ICLR, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Seq2Seq: Application to Program Execution (Zaremba et al.)\n",
    "- The network learns to execute simple codes without using any compiler or interpreter.\n",
    "<img src=\"images/python2.png\" />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Zaremba et al, \"Learning to Execute\", ICLR, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Image Caption Generation (Vinyals et al.)\n",
    "- Goal: Generate a text that describes a given image\n",
    "- Idea proposed by Vinyals et al.\n",
    "  - Use a pre-trained CNN to extract image features\n",
    "  - RNN part is a typical language model, but it is conditioned on the image feature.\n",
    "<img src=\"images/image_caption.png\" />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Vinyals et al., \"Show and Tell: A Neural Image Caption Generator\", CVPR, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Image Caption Generation (Vinyals et al.)\n",
    "<img src=\"images/image_caption2.png\" width=1000px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Vinyals et al, \"Show and Tell: A Neural Image Caption Generator\", CVPR, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Image Caption Generation (Xu et al.)\n",
    "- Another idea proposed by Xu et al. \n",
    "  - The model is forced to pay attention to only a part of the image when generating a word at a time.\n",
    "<img src=\"images/image_caption3.png\" width=700px />\n",
    "<img src=\"images/image_caption4.png\" width=700px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Xu et al, \"Show, Attend and Tell: Neural Image Caption\n",
    "Generation with Visual Attention\", ICML, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Image Caption Generation (Xu et al.)\n",
    "\n",
    "<img src=\"images/image_caption5.png\" width=900px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Xu et al, \"Show, Attend and Tell: Neural Image Caption\n",
    "Generation with Visual Attention\", ICML, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Image Caption Generation (Kiros et al.)\n",
    "- Some examples from Kiros et al.\n",
    "<img src=\"images/image_caption6.png\" width=800px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figures from Ruslan Salakhutdinov)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Outline\n",
    "\n",
    "- Motivation\n",
    "- Basics of Neural Networks\n",
    "  - Forward Propagation\n",
    "  - Backward Propagation\n",
    "- Deep Neural Networks\n",
    "  - Convolutional Neural Networks\n",
    "  - Recurrent Neural Networks\n",
    "- Applications\n",
    "  - Computer Vision\n",
    "  - Natural Language Processing\n",
    "  - **Reinforcement Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reinforcement Learning\n",
    "- An agent observes a state $s_t$, chooses an action $a_t$, receives a reward $r_t$, and goes to the next state $s_{t+1}$.\n",
    "- The goal is to learn an optimal policy that maximizes the total reward until the episode terminates (episodic task).\n",
    "<img src=\"images/rl.png\" width=600px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from \"Reinforcement Learning: An Introduction\" by Richard S. Sutton and Andrew G. Barto)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Deep Q-Network (Minh et al.)\n",
    "- A recent breakthrough from Google DeepMind\n",
    "- Combines Q-Learning with deep neural networks\n",
    "<img src=\"images/dqn.png\" width=300px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Minh et al. \"Human-level control through deep reinforcement learning\", Nature, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Brief Summary of Q-Learning\n",
    "- $Q(s,a)$: expected future reward when choosing action $a$ at state $s$.\n",
    "- The agent learns to estimate $Q(s,a)$ based on Bellman equation.\n",
    "- During evaluation, it chooses $\\mbox{argmax}_a Q(s,a)$ (greedy policy).\n",
    "- Problem: need to approximate $Q(s,a)$ when the state space is very large.\n",
    "<img src=\"images/rl.png\" width=600px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from \"Reinforcement Learning: An Introduction\" by Richard S. Sutton and Andrew G. Barto)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Deep Q-Network (Minh et al.)\n",
    "- Key idea: Use a CNN to approximate Q-values\n",
    "- Result\n",
    "    - Outperforms all existing (model-free) controllers\n",
    "    - Achieves human-level performances on many Atari 2600 games\n",
    "<img src=\"images/dqn2.png\" width=700px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Minh et al. \"Human-level control through deep reinforcement learning\", Nature, 2015.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### AlphaGo (Silver et al.)\n",
    "- Another breakthrough from Google DeepMind\n",
    "- Combines Monte-Carlo Tree Search (MTCS) with deep neural networks\n",
    "<img src=\"images/alphago.jpg\" width=300px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Silver et al., \"Mastering the game of Go with deep neural networks and tree search\", Nature, 2016.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Brief Summary of Monte-Carlo Tree Search (MTCS)\n",
    "- Idea: Simulate many possible futures and choose the best action\n",
    "- Problem: search space is too large!\n",
    "  - Should search over only a reasonable state space (tree policy should be reasonable).\n",
    "  - Should search up to a certain depth and use a default policy (usually random) to get the outcome.\n",
    "<img src=\"images/alphago2.png\" width=700px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Browne et al.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### AlphaGo (Silver et al.)\n",
    "0. Supervised Learning: Train a **policy network** to predict human experts' moves.\n",
    "0. Reinforcement Learning: Improve the policy network through self-play.\n",
    "0. Reinforcement Learning: Train a **value network** to predict whether the agent wins at the end or not.\n",
    "0. Use the learned networks to do MCTS more efficiently!\n",
    "<img src=\"images/alphago3.png\" width=800px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Silver et al., \"Mastering the game of Go with deep neural networks and tree search\", Nature, 2016.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### AlphaGo (Silver et al.)\n",
    "- Use the **policy network** as a prior distribution over actions.\n",
    "  - Allows searching over only reasonable state spaces.\n",
    "- Use the **value network** to directly predict the outcome at the leaf node.\n",
    "- Use a shallow but fast policy network as a default policy. (better than random)\n",
    "<img src=\"images/alphago2.png\" width=700px />\n",
    "<span style=\"color:gray; font-size:10px; float:right\">(Figure from Browne et al.)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### AlphaGo (Silver et al.)\n",
    "- Result: AlphaGo beat Lee Sedol (the world’s top Go player).\n",
    "<img src=\"images/alphago5.jpg\", width=400px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Summary \n",
    "- Deep Learning: machine learning algorithms based on learning multiple levels of representation.\n",
    "- Neural networks can implement the idea of deep learning in a very flexible way.\n",
    "- Deep neural networks (e.g., CNN, RNN) have made remarkable advances in computer vision, natural language processing, and reinforcement learning area."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
